{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vperls000/csc44800/blob/main/Viviana_Perls_Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vperls000/csc44800/blob/main/Viviana_Perls_Assignment4.ipynb)"
      ],
      "metadata": {
        "id": "remAwYALqI7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8PKiVJaL_AW"
      },
      "outputs": [],
      "source": [
        "# Imports and pip installations (if needed)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A05Q5B0_NUX9"
      },
      "source": [
        "# Part 1: Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ4MUsbXNZ0P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "d758e697-b36b-44fe-9ee8-e674e757ce24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal length  sepal width  petal length  petal width      species\n",
              "0            5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1            4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2            4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3            4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4            5.0          3.6           1.4          0.2  Iris-setosa\n",
              "5            5.4          3.9           1.7          0.4  Iris-setosa\n",
              "6            4.6          3.4           1.4          0.3  Iris-setosa\n",
              "7            5.0          3.4           1.5          0.2  Iris-setosa\n",
              "8            4.4          2.9           1.4          0.2  Iris-setosa\n",
              "9            4.9          3.1           1.5          0.1  Iris-setosa\n",
              "10           5.4          3.7           1.5          0.2  Iris-setosa\n",
              "11           4.8          3.4           1.6          0.2  Iris-setosa\n",
              "12           4.8          3.0           1.4          0.1  Iris-setosa\n",
              "13           4.3          3.0           1.1          0.1  Iris-setosa\n",
              "14           5.8          4.0           1.2          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-687b12a4-b1c9-4b19-83ca-575966e46497\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-687b12a4-b1c9-4b19-83ca-575966e46497')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-687b12a4-b1c9-4b19-83ca-575966e46497 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-687b12a4-b1c9-4b19-83ca-575966e46497');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Load the dataset (load remotely, not locally)\n",
        "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "column_names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'species']\n",
        "iris = pd.read_csv(csv_url,names=column_names)\n",
        "\n",
        "# Output the first 15 rows of the data\n",
        "iris.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a summary of the table information (number of datapoints, etc.)\n",
        "print(iris.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tLtqA4dxBYG",
        "outputId": "aa280c6d-89f8-4d29-f7db-f82a7679554e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       sepal length  sepal width  petal length  petal width\n",
            "count    150.000000   150.000000    150.000000   150.000000\n",
            "mean       5.843333     3.054000      3.758667     1.198667\n",
            "std        0.828066     0.433594      1.764420     0.763161\n",
            "min        4.300000     2.000000      1.000000     0.100000\n",
            "25%        5.100000     2.800000      1.600000     0.300000\n",
            "50%        5.800000     3.000000      4.350000     1.300000\n",
            "75%        6.400000     3.300000      5.100000     1.800000\n",
            "max        7.900000     4.400000      6.900000     2.500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRMtsJKBaxWu"
      },
      "source": [
        "## About the dataset\n",
        "The Iris Dataset is a commonly used toy dataset which contains 150 samples of irises of the species Setosa, Versicolor, and Virginica- where each species has 50 samples within the dataset.  The species will be classified into groups {0,1,2}, where 0 = Setosa, 1 = Versicolor, and 2 = Virginica.  The features of these irises are sepal length, sepal width, petal length, and petal width."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhKaIrZKNaHg"
      },
      "source": [
        "# Part 2: Split the dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrgogB62NcOi"
      },
      "outputs": [],
      "source": [
        "# Take the dataset and split it into our features (X) and label (y)\n",
        "X = iris[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
        "Y = iris['species']\n",
        "\n",
        "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.1, train_size=.9, random_state=0, shuffle=True, stratify=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here I am defining the sample datapoint that I will be using to predict the\n",
        "# probabilities for each possible class in each model.\n",
        "X_sample = [[7.900000,4.400000,6.900000,2.500000]]\n",
        "X_pred = pd.DataFrame(X_sample, columns=X_test.columns)"
      ],
      "metadata": {
        "id": "uvV9U0uV316Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hblF-ei9Ncia"
      },
      "source": [
        "# Part 3: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhFhEN03Nf7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6cbf72-0cf4-471d-90d8-0cf3fe364e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setosa probability:  3.7740018393379437e-08\n",
            "Versicolor probability:  0.001185918144024011\n",
            "Virginica probability:  0.9988140441159576\n",
            "Score:  1.0\n",
            "Coefficients:  [[-0.41035194  0.92087293 -2.43647188 -1.05570355]\n",
            " [ 0.40249086 -0.32260361 -0.11298067 -0.88152875]\n",
            " [ 0.00786108 -0.59826933  2.54945255  1.9372323 ]]\n",
            "Intercepts:  [  9.49196592   2.42958512 -11.92155104]\n"
          ]
        }
      ],
      "source": [
        "# i. Use sklearn to train a LogisticRegression model on the training set\n",
        "reg = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "y_pred_reg = reg.predict_proba(X_pred)\n",
        "print('Setosa probability: ', y_pred_reg[0][0])\n",
        "print('Versicolor probability: ', y_pred_reg[0][1])\n",
        "print('Virginica probability: ', y_pred_reg[0][2])\n",
        "\n",
        "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
        "print('Score: ', reg.score(X_test,y_test))\n",
        "\n",
        "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
        "print('Coefficients: ', reg.coef_)\n",
        "print('Intercepts: ', reg.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score of the Logistic Regression model is the mean accuracy of the model given the test data.  In this instance, the score is 1, meaning that (on average) the model can classify data from X_test with 100% accuracy."
      ],
      "metadata": {
        "id": "eqfH-uMJ4_pT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDUpXQN4Nilk"
      },
      "source": [
        "# Part 4: Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U__zukpdNqiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb64d08-57d9-4c1e-cae6-3059411066de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setosa probability:  0.028066488976037213\n",
            "Versicolor probability:  0.007891656689803603\n",
            "Virginica probability:  0.9640418543341593\n",
            "Score:  1.0\n"
          ]
        }
      ],
      "source": [
        "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
        "svc = svm.SVC(probability=True).fit(X_train,y_train)\n",
        "\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "y_pred_svc = svc.predict_proba(X_pred)\n",
        "print('Setosa probability: ', y_pred_svc[0][0])\n",
        "print('Versicolor probability: ', y_pred_svc[0][1])\n",
        "print('Virginica probability: ', y_pred_svc[0][2])\n",
        "\n",
        "# iii. Report on the score for the SVM, what does the score measure?\n",
        "print('Score: ', svc.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score measures the same mean accuracy as in the Logistic Regression model, as it does in all of the models in this assignment.  This score is also 1, meaning that the accuracy is 100%.  However, looking at the prediction probabilities for each possible class, the same sample has a probability of 96% for the Virginica species, and 99% of the same in the Logistic Regression model.  Therefore, the two have the same mean accuracy, but perhaps the Logistic Regression model would be more accurate given a larger set of test data."
      ],
      "metadata": {
        "id": "LcdSJ-ao5L1I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULoL7mMBNrlS"
      },
      "source": [
        "# Part 5: Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKKmODVrN9lQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb224c3-0c60-4dba-b478-94e95b232a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setosa probability:  5.006597396348999e-07\n",
            "Versicolor probability:  0.0036177365516225865\n",
            "Virginica probability:  0.9963817627886379\n",
            "Score:  1.0\n"
          ]
        }
      ],
      "source": [
        "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
        "net = MLPClassifier(random_state=0,max_iter=750).fit(X_train,y_train)\n",
        "\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "y_pred_net = net.predict_proba(X_pred)\n",
        "print('Setosa probability: ', y_pred_net[0][0])\n",
        "print('Versicolor probability: ', y_pred_net[0][1])\n",
        "print('Virginica probability: ', y_pred_net[0][2])\n",
        "\n",
        "# iii. Report on the score for the Neural Network, what does the score measure?\n",
        "print('Score: ',net.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score is again 1 in this Neutal Net model, which again means 100% accuracy.  For the individual sample, the predicted probability of the Virginica species is 99%, indicating more similarity to the Logistic Regression model than to the Support Vector Machine model."
      ],
      "metadata": {
        "id": "zKnGgKKG7uWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimenting with max_iter value\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=300).fit(X_train,y_train)\n",
        "print('Score when max_iter=300: ',net.score(X_test,y_test))\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=200).fit(X_train,y_train)\n",
        "print('Score when max_iter=200: ',net.score(X_test,y_test))\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=100).fit(X_train,y_train)\n",
        "print('Score when max_iter=100: ',net.score(X_test,y_test))\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=110).fit(X_train,y_train)\n",
        "print('Score when max_iter=110: ',net.score(X_test,y_test))\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=115).fit(X_train,y_train)\n",
        "print('Score when max_iter=115: ',net.score(X_test,y_test))\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=120).fit(X_train,y_train)\n",
        "print('Score when max_iter=120: ',net.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Soqdm9AB7zqX",
        "outputId": "d1885802-5803-4bc9-fcf1-02bd9480ead7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score when max_iter=300:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score when max_iter=200:  1.0\n",
            "Score when max_iter=100:  0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (110) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (115) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score when max_iter=110:  0.8666666666666667\n",
            "Score when max_iter=115:  0.9333333333333333\n",
            "Score when max_iter=120:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the original Neural Net model, I set max_iter to 750 to avoid a convergence warning.  In the two models above, I lowered the number of max iterations to see at about what point the score dips below 1.  It seems that past about 115 iterations is when the model becomes 100% accurate."
      ],
      "metadata": {
        "id": "F3RFEyFBFG_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimenting with hidden_layer_sizes\n",
        "# max_iter = 750\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=750,hidden_layer_sizes=1).fit(X_train,y_train)\n",
        "print('Score when hidden_layer_sizes=1: ', net.score(X_test,y_test))\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=750,hidden_layer_sizes=5).fit(X_train,y_train)\n",
        "print('\\nScore when hidden_layer_sizes=5: ', net.score(X_test,y_test))\n",
        "\n",
        "net = MLPClassifier(random_state=0,max_iter=750,hidden_layer_sizes=10).fit(X_train,y_train)\n",
        "print('\\nScore when hidden_layer_sizes=10: ', net.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAo2coCa0-GG",
        "outputId": "e031a2a6-3bb0-4fd4-a5fe-34027df926cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (750) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score when hidden_layer_sizes=1:  0.4666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (750) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score when hidden_layer_sizes=5:  0.8666666666666667\n",
            "Score when hidden_layer_sizes=10:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (750) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I repeated the process by changing the number of hidden layers to see when the score dips below 1, making sure to keep max_iter at 750 for each model.  From these tests, I noticed that the range of hidden layer sizes was much smaller here than the range of max iterations."
      ],
      "metadata": {
        "id": "NIt5MWdOGQX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimenting with both max_iter and hidden_layer_size\n",
        "\n",
        "net= MLPClassifier(random_state=0,max_iter=1000,hidden_layer_sizes=1).fit(X_train,y_train)\n",
        "print('Score when max_iter=1000, hidden_layer_sizes=1: ', net.score(X_test,y_test))\n",
        "\n",
        "net= MLPClassifier(random_state=0,max_iter=2000,hidden_layer_sizes=1).fit(X_train,y_train)\n",
        "print('Score when max_iter=2000, hidden_layer_sizes=1: ', net.score(X_test,y_test))\n",
        "\n",
        "net= MLPClassifier(random_state=0,max_iter=3000,hidden_layer_sizes=1).fit(X_train,y_train)\n",
        "print('Score when max_iter=3000, hidden_layer_sizes=1: ', net.score(X_test,y_test))\n",
        "\n",
        "net= MLPClassifier(random_state=0,max_iter=1000,hidden_layer_sizes=5).fit(X_train,y_train)\n",
        "print('Score when max_iter=1000, hidden_layer_sizes=5: ', net.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7cPCrEM1MdW",
        "outputId": "d8c399a2-0ba0-4530-e069-6ff94280f386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score when max_iter=1000, hidden_layer_sizes=1:  0.4666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score when max_iter=2000, hidden_layer_sizes=1:  0.6\n",
            "Score when max_iter=3000, hidden_layer_sizes=1:  0.6\n",
            "Score when max_iter=1000, hidden_layer_sizes=5:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the tests where I only changed the hidden layer sizes, I noticed that I got convergence warnings where I hadn't in the original model, so I decided to try increasing the number of max iterations until the score changes or until the convergence warning went away.  From the tests above, it's clear that the less hidden layers there are, the more iterations may be necessary to avoid a convergence warning or to get a good score."
      ],
      "metadata": {
        "id": "O-ag6Bma2RIp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bi5tDwHmC28"
      },
      "source": [
        "# Part 6: K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCFlfJy2mCg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149ec175-e8d1-46f5-a643-f98c28de89ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setosa probability:  0.0\n",
            "Versicolor probability:  0.0\n",
            "Virginica probability:  1.0\n",
            "\n",
            "Score:  1.0\n"
          ]
        }
      ],
      "source": [
        "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
        "# Note: KNN is a nonparametric model and technically doesn't require training\n",
        "# fit will essentially load the data into the model see link below for more information\n",
        "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
        "\n",
        "knn = KNeighborsClassifier().fit(X_train,y_train)\n",
        "\n",
        "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
        "y_pred_knn = knn.predict_proba(X_pred)\n",
        "print('Setosa probability: ', y_pred_knn[0][0])\n",
        "print('Versicolor probability: ', y_pred_knn[0][1])\n",
        "print('Virginica probability: ', y_pred_knn[0][2])\n",
        "\n",
        "# iii. Report on the score for kNN, what does the score measure?\n",
        "print('\\nScore: ', knn.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score for this K-Nearest Neighbors model was 1, but even more interestingly the prediction probabilities for the individual sample gave the Virginica species 100% probability.  I would assume that the sample I used (which was also the maximum from the summary table) only had neighbors that were of the Virginica species."
      ],
      "metadata": {
        "id": "CzLKULIa326-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162Sw3LeoqE2"
      },
      "source": [
        "# Part 7: Conclusions and takeaways\n",
        "\n",
        "Most of the models had a score of 1, which I expect is because the ratio of training to testing data is so high.  Based on the predicted probabilities of the individual sample, I would say that Logistic Regression and Support Machine worked best.  I am tempted to say the same for K-Nearest Neighbors, but I am not sure that this would be true if the sample I used was the mean from the summary.  I think KNN performed so well with my tests because my tests included very little data and therefore did not show what would happen if a datapoint was sort of in the middle of the distribution.  I was surprised to see how accurate every model was, but again I think this had to do with the small amount of test data in comparison to the training data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Viviana_Perls_Assignment4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}